use bytemuck::{Pod, Zeroable};
use glam::{Mat3, Vec2, Vec3};
use image::{DynamicImage, GenericImageView, Rgba, Rgb32FImage};
use imageproc::geometric_transformations::{rotate_about_center, Interpolation};
use rawler::decoders::Orientation;
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use serde_json::json;
use serde_json::Value;
use std::f32::consts::PI;
use std::sync::Arc;

pub use crate::gpu_processing::{get_or_init_gpu_context, process_and_get_dynamic_image};
use crate::{load_settings, mask_generation::MaskDefinition, AppState};

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ImageMetadata {
    pub version: u32,
    pub rating: u8,
    pub adjustments: Value,
    #[serde(default)]
    pub tags: Option<Vec<String>>,
}

impl Default for ImageMetadata {
    fn default() -> Self {
        ImageMetadata {
            version: 1,
            rating: 0,
            adjustments: Value::Null,
            tags: None,
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy)]
pub struct Crop {
    pub x: f64,
    pub y: f64,
    pub width: f64,
    pub height: f64,
}

pub fn downscale_f32_image(image: &DynamicImage, nwidth: u32, nheight: u32) -> DynamicImage {
    let (width, height) = image.dimensions();
    if nwidth == 0 || nheight == 0 {
        return image.clone();
    }
    if nwidth >= width && nheight >= height {
        return image.clone();
    }

    let ratio = (nwidth as f32 / width as f32).min(nheight as f32 / height as f32);
    let new_w = (width as f32 * ratio).round() as u32;
    let new_h = (height as f32 * ratio).round() as u32;

    if new_w == 0 || new_h == 0 {
        return image.clone();
    }

    let img = image.to_rgb32f();
    let mut out = Rgb32FImage::new(new_w, new_h);

    let x_ratio = width as f32 / new_w as f32;
    let y_ratio = height as f32 / new_h as f32;

    for y_out in 0..new_h {
        for x_out in 0..new_w {
            let x_start = (x_out as f32 * x_ratio).floor() as u32;
            let y_start = (y_out as f32 * y_ratio).floor() as u32;
            let x_end = ((x_out + 1) as f32 * x_ratio).ceil() as u32;
            let y_end = ((y_out + 1) as f32 * y_ratio).ceil() as u32;

            let mut r_sum = 0.0;
            let mut g_sum = 0.0;
            let mut b_sum = 0.0;
            let mut count = 0.0;

            for y_in in y_start..y_end.min(height) {
                for x_in in x_start..x_end.min(width) {
                    let pixel = img.get_pixel(x_in, y_in);
                    r_sum += pixel[0];
                    g_sum += pixel[1];
                    b_sum += pixel[2];
                    count += 1.0;
                }
            }

            if count > 0.0 {
                out.put_pixel(
                    x_out,
                    y_out,
                    image::Rgb([r_sum / count, g_sum / count, b_sum / count]),
                );
            }
        }
    }
    DynamicImage::ImageRgb32F(out)
}

pub fn apply_cpu_default_raw_processing(image: &mut DynamicImage) {
    let mut f32_image = image.to_rgb32f();

    const GAMMA: f32 = 2.2;
    const INV_GAMMA: f32 = 1.0 / GAMMA;
    const CONTRAST: f32 = 1.15;

    f32_image.par_chunks_mut(3).for_each(|pixel_chunk| {
        let r_gamma = pixel_chunk[0].powf(INV_GAMMA);
        let g_gamma = pixel_chunk[1].powf(INV_GAMMA);
        let b_gamma = pixel_chunk[2].powf(INV_GAMMA);

        let r_contrast = (r_gamma - 0.5) * CONTRAST + 0.5;
        let g_contrast = (g_gamma - 0.5) * CONTRAST + 0.5;
        let b_contrast = (b_gamma - 0.5) * CONTRAST + 0.5;

        pixel_chunk[0] = r_contrast.clamp(0.0, 1.0);
        pixel_chunk[1] = g_contrast.clamp(0.0, 1.0);
        pixel_chunk[2] = b_contrast.clamp(0.0, 1.0);
    });

    *image = DynamicImage::ImageRgb32F(f32_image);
}

pub fn apply_orientation(image: DynamicImage, orientation: Orientation) -> DynamicImage {
    match orientation {
        Orientation::Normal | Orientation::Unknown => image,
        Orientation::HorizontalFlip => image.fliph(),
        Orientation::Rotate180 => image.rotate180(),
        Orientation::VerticalFlip => image.flipv(),
        Orientation::Transpose => image.rotate90().flipv(),
        Orientation::Rotate90 => image.rotate90(),
        Orientation::Transverse => image.rotate90().fliph(),
        Orientation::Rotate270 => image.rotate270(),
    }
}

pub fn apply_coarse_rotation(image: DynamicImage, orientation_steps: u8) -> DynamicImage {
    match orientation_steps {
        1 => image.rotate90(),
        2 => image.rotate180(),
        3 => image.rotate270(),
        _ => image,
    }
}

pub fn apply_rotation(image: &DynamicImage, rotation_degrees: f32) -> DynamicImage {
    if rotation_degrees % 360.0 == 0.0 {
        return image.clone();
    }

    let rgba_image = image.to_rgba32f();

    let rotated = rotate_about_center(
        &rgba_image,
        rotation_degrees * PI / 180.0,
        Interpolation::Bilinear,
        Rgba([0.0f32, 0.0, 0.0, 0.0]),
    );

    DynamicImage::ImageRgba32F(rotated)
}

pub fn apply_crop(mut image: DynamicImage, crop_value: &Value) -> DynamicImage {
    if crop_value.is_null() {
        return image;
    }
    if let Ok(crop) = serde_json::from_value::<Crop>(crop_value.clone()) {
        let x = crop.x.round() as u32;
        let y = crop.y.round() as u32;
        let width = crop.width.round() as u32;
        let height = crop.height.round() as u32;

        if width > 0 && height > 0 {
            let (img_w, img_h) = image.dimensions();
            if x < img_w && y < img_h {
                let new_width = (img_w - x).min(width);
                let new_height = (img_h - y).min(height);
                if new_width > 0 && new_height > 0 {
                    image = image.crop_imm(x, y, new_width, new_height);
                }
            }
        }
    }
    image
}

pub fn apply_flip(image: DynamicImage, horizontal: bool, vertical: bool) -> DynamicImage {
    let mut img = image;
    if horizontal {
        img = img.fliph();
    }
    if vertical {
        img = img.flipv();
    }
    img
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AutoAdjustmentResults {
    pub exposure: f64,
    pub contrast: f64,
    pub highlights: f64,
    pub shadows: f64,
    pub vibrancy: f64,
    pub vignette_amount: f64,
    pub temperature: f64,
    pub tint: f64,
    pub dehaze: f64,
    pub clarity: f64,
    pub centre: f64,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct Point {
    x: f32,
    y: f32,
    _pad1: f32,
    _pad2: f32,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct HslColor {
    hue: f32,
    saturation: f32,
    luminance: f32,
    _pad: f32,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct ColorGradeSettings {
    pub hue: f32,
    pub saturation: f32,
    pub luminance: f32,
    _pad: f32,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct ColorCalibrationSettings {
    pub shadows_tint: f32,
    pub red_hue: f32,
    pub red_saturation: f32,
    pub green_hue: f32,
    pub green_saturation: f32,
    pub blue_hue: f32,
    pub blue_saturation: f32,
    _pad1: f32,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable)]
#[repr(C)]
pub struct GpuMat3 {
    col0: [f32; 4],
    col1: [f32; 4],
    col2: [f32; 4],
}

impl Default for GpuMat3 {
    fn default() -> Self {
        Self {
            col0: [1.0, 0.0, 0.0, 0.0],
            col1: [0.0, 1.0, 0.0, 0.0],
            col2: [0.0, 0.0, 1.0, 0.0],
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct GlobalAdjustments {
    pub exposure: f32,
    pub brightness: f32,
    pub contrast: f32,
    pub highlights: f32,
    pub shadows: f32,
    pub whites: f32,
    pub blacks: f32,
    pub saturation: f32,
    pub temperature: f32,
    pub tint: f32,
    pub vibrance: f32,

    pub sharpness: f32,
    pub luma_noise_reduction: f32,
    pub color_noise_reduction: f32,
    pub clarity: f32,
    pub dehaze: f32,
    pub structure: f32,
    pub centré: f32,
    pub vignette_amount: f32,
    pub vignette_midpoint: f32,
    pub vignette_roundness: f32,
    pub vignette_feather: f32,
    pub grain_amount: f32,
    pub grain_size: f32,
    pub grain_roughness: f32,

    pub chromatic_aberration_red_cyan: f32,
    pub chromatic_aberration_blue_yellow: f32,
    pub show_clipping: u32,
    pub is_raw_image: u32,

    pub enable_negative_conversion: u32,
    pub film_base_r: f32,
    pub film_base_g: f32,
    pub film_base_b: f32,
    pub negative_red_balance: f32,
    pub negative_green_balance: f32,
    pub negative_blue_balance: f32,
    _pad_neg1: f32,
    _pad_neg2: f32,

    pub has_lut: u32,
    pub lut_intensity: f32,
    pub tonemapper_mode: u32,
    _pad_lut2: f32,
    _pad_lut3: f32,
    _pad_lut4: f32,
    _pad_lut5: f32,

    _pad_agx1: f32,
    _pad_agx2: f32,
    _pad_agx3: f32,
    pub agx_pipe_to_rendering_matrix: GpuMat3,
    pub agx_rendering_to_pipe_matrix: GpuMat3,

    _pad_cg1: f32,
    _pad_cg2: f32,
    _pad_cg3: f32,
    _pad_cg4: f32,
    pub color_grading_shadows: ColorGradeSettings,
    pub color_grading_midtones: ColorGradeSettings,
    pub color_grading_highlights: ColorGradeSettings,
    pub color_grading_blending: f32,
    pub color_grading_balance: f32,
    _pad2: f32,
    _pad3: f32,

    pub color_calibration: ColorCalibrationSettings,

    // Low-Light Recovery: Hot Pixels
    pub hot_pixel_enabled: u32,
    pub hot_pixel_threshold: f32,
    pub hot_pixel_radius: f32,
    pub hot_pixel_mode: u32,

    // Denoiser (ISO-adaptive)
    pub denoise_enabled: u32,
    pub denoise_strength: f32,
    pub denoise_detail: f32,
    pub denoise_chroma: f32,
    pub denoise_iso_multiplier: f32,
    _pad_denoise1: f32,
    _pad_denoise2: f32,
    _pad_denoise3: f32,

    // PID Enhancement: Smart Deblur
    pub deblur_enabled: u32,
    pub deblur_type: u32,
    pub deblur_length: f32,
    pub deblur_angle: f32,
    pub deblur_radius: f32,
    pub deblur_strength: f32,
    pub deblur_smoothness: f32,
    pub deblur_noise_damp: f32,
    pub deblur_preview_size: f32,
    pub deblur_show_kernel: u32,
    pub deblur_iterations: u32,
    pub _pad_deblur2: f32,

    pub hsl: [HslColor; 8],
    pub luma_curve: [Point; 16],
    pub red_curve: [Point; 16],
    pub green_curve: [Point; 16],
    pub blue_curve: [Point; 16],
    pub luma_curve_count: u32,
    pub red_curve_count: u32,
    pub green_curve_count: u32,
    pub blue_curve_count: u32,
    _pad_end1: f32,
    _pad_end2: f32,
    _pad_end3: f32,
    _pad_end4: f32,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct MaskAdjustments {
    pub exposure: f32,
    pub brightness: f32,
    pub contrast: f32,
    pub highlights: f32,
    pub shadows: f32,
    pub whites: f32,
    pub blacks: f32,
    pub saturation: f32,
    pub temperature: f32,
    pub tint: f32,
    pub vibrance: f32,

    pub sharpness: f32,
    pub luma_noise_reduction: f32,
    pub color_noise_reduction: f32,
    pub clarity: f32,
    pub dehaze: f32,
    pub structure: f32,

    _pad1: f32,
    _pad2: f32,
    _pad3: f32,
    _pad4: f32,

    _pad_cg1: f32,
    _pad_cg2: f32,
    _pad_cg3: f32,
    pub color_grading_shadows: ColorGradeSettings,
    pub color_grading_midtones: ColorGradeSettings,
    pub color_grading_highlights: ColorGradeSettings,
    pub color_grading_blending: f32,
    pub color_grading_balance: f32,
    _pad5: f32,
    _pad6: f32,

    // PID Enhancement (mask-supported)
    pub deblur_strength: f32,
    pub deblur_smoothness: f32,
    _pad_pid1: f32,
    _pad_pid2: f32,

    pub hsl: [HslColor; 8],
    pub luma_curve: [Point; 16],
    pub red_curve: [Point; 16],
    pub green_curve: [Point; 16],
    pub blue_curve: [Point; 16],
    pub luma_curve_count: u32,
    pub red_curve_count: u32,
    pub green_curve_count: u32,
    pub blue_curve_count: u32,
    _pad_end4: f32,
    _pad_end5: f32,
    _pad_end6: f32,
    _pad_end7: f32,
}

#[derive(Debug, Clone, Copy, Pod, Zeroable, Default)]
#[repr(C)]
pub struct AllAdjustments {
    pub global: GlobalAdjustments,
    pub mask_adjustments: [MaskAdjustments; 11],
    pub mask_count: u32,
    pub tile_offset_x: u32,
    pub tile_offset_y: u32,
    pub mask_atlas_cols: u32,
}

struct AdjustmentScales {
    exposure: f32,
    brightness: f32,
    contrast: f32,
    highlights: f32,
    shadows: f32,
    whites: f32,
    blacks: f32,
    saturation: f32,
    temperature: f32,
    tint: f32,
    vibrance: f32,

    sharpness: f32,
    luma_noise_reduction: f32,
    color_noise_reduction: f32,
    clarity: f32,
    dehaze: f32,
    structure: f32,
    centré: f32,

    vignette_amount: f32,
    vignette_midpoint: f32,
    vignette_roundness: f32,
    vignette_feather: f32,
    grain_amount: f32,
    grain_size: f32,
    grain_roughness: f32,

    chromatic_aberration: f32,

    hsl_hue_multiplier: f32,
    hsl_saturation: f32,
    hsl_luminance: f32,

    color_grading_saturation: f32,
    color_grading_luminance: f32,
    color_grading_blending: f32,
    color_grading_balance: f32,

    color_calibration_hue: f32,
    color_calibration_saturation: f32,

    // Low-Light Recovery scales
    hot_pixel_threshold: f32,
    hot_pixel_radius: f32,
    denoise_strength: f32,
    denoise_detail: f32,
    denoise_chroma: f32,

    // PID Enhancement scales
    deblur_length: f32,
    deblur_radius: f32,
    deblur_strength: f32,
    deblur_smoothness: f32,
    deblur_noise_damp: f32,
}

const SCALES: AdjustmentScales = AdjustmentScales {
    exposure: 0.8,
    brightness: 0.8,
    contrast: 100.0,
    highlights: 150.0,
    shadows: 100.0,
    whites: 30.0,
    blacks: 60.0,
    saturation: 100.0,
    temperature: 25.0,
    tint: 100.0,
    vibrance: 100.0,

    sharpness: 80.0,
    luma_noise_reduction: 100.0,
    color_noise_reduction: 100.0,
    clarity: 200.0,
    dehaze: 750.0,
    structure: 200.0,
    centré: 250.0,

    vignette_amount: 100.0,
    vignette_midpoint: 100.0,
    vignette_roundness: 100.0,
    vignette_feather: 100.0,
    grain_amount: 200.0,
    grain_size: 50.0,
    grain_roughness: 100.0,

    chromatic_aberration: 10000.0,

    hsl_hue_multiplier: 0.3,
    hsl_saturation: 100.0,
    hsl_luminance: 100.0,

    color_grading_saturation: 500.0,
    color_grading_luminance: 500.0,
    color_grading_blending: 100.0,
    color_grading_balance: 200.0,

    color_calibration_hue: 400.0,
    color_calibration_saturation: 120.0,

    // Low-Light Recovery scales
    hot_pixel_threshold: 100.0,
    hot_pixel_radius: 1.0,
    // Denoise: shader expects 0-100 values, so scale is 1.0
    denoise_strength: 1.0,
    denoise_detail: 1.0,
    denoise_chroma: 1.0,

    // PID Enhancement scales
    deblur_length: 1.0,  // pixels, no division needed
    deblur_radius: 1.0,  // pixels, no division needed
    // Smart Deblur: shader expects 0-100 values
    deblur_strength: 1.0,
    deblur_smoothness: 1.0,
    deblur_noise_damp: 1.0,
};

fn parse_hsl_adjustments(js_hsl: &serde_json::Value) -> [HslColor; 8] {
    let mut hsl_array = [HslColor::default(); 8];
    if let Some(hsl_map) = js_hsl.as_object() {
        let color_map = [
            ("reds", 0),
            ("oranges", 1),
            ("yellows", 2),
            ("greens", 3),
            ("aquas", 4),
            ("blues", 5),
            ("purples", 6),
            ("magentas", 7),
        ];
        for (name, index) in color_map.iter() {
            if let Some(color_data) = hsl_map.get(*name) {
                hsl_array[*index] = HslColor {
                    hue: color_data["hue"].as_f64().unwrap_or(0.0) as f32
                        * SCALES.hsl_hue_multiplier,
                    saturation: color_data["saturation"].as_f64().unwrap_or(0.0) as f32
                        / SCALES.hsl_saturation,
                    luminance: color_data["luminance"].as_f64().unwrap_or(0.0) as f32
                        / SCALES.hsl_luminance,
                    _pad: 0.0,
                };
            }
        }
    }
    hsl_array
}

fn parse_color_grade_settings(js_cg: &serde_json::Value) -> ColorGradeSettings {
    if js_cg.is_null() {
        return ColorGradeSettings::default();
    }
    ColorGradeSettings {
        hue: js_cg["hue"].as_f64().unwrap_or(0.0) as f32,
        saturation: js_cg["saturation"].as_f64().unwrap_or(0.0) as f32
            / SCALES.color_grading_saturation,
        luminance: js_cg["luminance"].as_f64().unwrap_or(0.0) as f32
            / SCALES.color_grading_luminance,
        _pad: 0.0,
    }
}

fn convert_points_to_aligned(frontend_points: Vec<serde_json::Value>) -> [Point; 16] {
    let mut aligned_points = [Point::default(); 16];
    for (i, point) in frontend_points.iter().enumerate().take(16) {
        if let (Some(x), Some(y)) = (point["x"].as_f64(), point["y"].as_f64()) {
            aligned_points[i] = Point {
                x: x as f32,
                y: y as f32,
                _pad1: 0.0,
                _pad2: 0.0,
            };
        }
    }
    aligned_points
}

const WP_D65: Vec2 = Vec2::new(0.3127, 0.3290);
const PRIMARIES_SRGB: [Vec2; 3] = [
    Vec2::new(0.64, 0.33),
    Vec2::new(0.30, 0.60),
    Vec2::new(0.15, 0.06),
];
const PRIMARIES_REC2020: [Vec2; 3] = [
    Vec2::new(0.708, 0.292),
    Vec2::new(0.170, 0.797),
    Vec2::new(0.131, 0.046),
];

fn xy_to_xyz(xy: Vec2) -> Vec3 {
    if xy.y < 1e-6 {
        Vec3::ZERO
    } else {
        Vec3::new(xy.x / xy.y, 1.0, (1.0 - xy.x - xy.y) / xy.y)
    }
}

fn primaries_to_xyz_matrix(primaries: &[Vec2; 3], white_point: Vec2) -> Mat3 {
    let r_xyz = xy_to_xyz(primaries[0]);
    let g_xyz = xy_to_xyz(primaries[1]);
    let b_xyz = xy_to_xyz(primaries[2]);
    let primaries_matrix = Mat3::from_cols(r_xyz, g_xyz, b_xyz);
    let white_point_xyz = xy_to_xyz(white_point);
    let s = primaries_matrix.inverse() * white_point_xyz;
    Mat3::from_cols(r_xyz * s.x, g_xyz * s.y, b_xyz * s.z)
}

fn rotate_and_scale_primary(primary: Vec2, white_point: Vec2, scale: f32, rotation: f32) -> Vec2 {
    let p_rel = primary - white_point;
    let p_scaled = p_rel * scale;
    let (sin_r, cos_r) = rotation.sin_cos();
    let p_rotated = Vec2::new(
        p_scaled.x * cos_r - p_scaled.y * sin_r,
        p_scaled.x * sin_r + p_scaled.y * cos_r,
    );
    white_point + p_rotated
}

fn mat3_to_gpu_mat3(m: Mat3) -> GpuMat3 {
    GpuMat3 {
        col0: [m.x_axis.x, m.x_axis.y, m.x_axis.z, 0.0],
        col1: [m.y_axis.x, m.y_axis.y, m.y_axis.z, 0.0],
        col2: [m.z_axis.x, m.z_axis.y, m.z_axis.z, 0.0],
    }
}

fn calculate_agx_matrices() -> (GpuMat3, GpuMat3) {
    let pipe_work_profile_to_xyz = primaries_to_xyz_matrix(&PRIMARIES_SRGB, WP_D65);
    let base_profile_to_xyz = primaries_to_xyz_matrix(&PRIMARIES_REC2020, WP_D65);
    let xyz_to_base_profile = base_profile_to_xyz.inverse();
    let pipe_to_base = xyz_to_base_profile * pipe_work_profile_to_xyz;

    let inset = [0.29462451, 0.25861925, 0.14641371];
    let rotation = [0.03540329, -0.02108586, -0.06305724];
    let outset = [0.290776401758, 0.263155400753, 0.045810721815];
    let unrotation = [0.03540329, -0.02108586, -0.06305724];
    let master_outset_ratio = 1.0;
    let master_unrotation_ratio = 0.0;

    let mut inset_and_rotated_primaries = [Vec2::ZERO; 3];
    for i in 0..3 {
        inset_and_rotated_primaries[i] =
            rotate_and_scale_primary(PRIMARIES_REC2020[i], WP_D65, 1.0 - inset[i], rotation[i]);
    }
    let rendering_to_xyz = primaries_to_xyz_matrix(&inset_and_rotated_primaries, WP_D65);
    let base_to_rendering = xyz_to_base_profile * rendering_to_xyz;

    let mut outset_and_unrotated_primaries = [Vec2::ZERO; 3];
    for i in 0..3 {
        outset_and_unrotated_primaries[i] = rotate_and_scale_primary(
            PRIMARIES_REC2020[i],
            WP_D65,
            1.0 - master_outset_ratio * outset[i],
            master_unrotation_ratio * unrotation[i],
        );
    }
    let outset_to_xyz = primaries_to_xyz_matrix(&outset_and_unrotated_primaries, WP_D65);
    let temp_matrix = xyz_to_base_profile * outset_to_xyz;
    let rendering_to_base = temp_matrix.inverse();

    let pipe_to_rendering = base_to_rendering * pipe_to_base;
    let rendering_to_pipe = pipe_to_base.inverse() * rendering_to_base;

    (
        mat3_to_gpu_mat3(pipe_to_rendering),
        mat3_to_gpu_mat3(rendering_to_pipe),
    )
}

fn get_global_adjustments_from_json(
    js_adjustments: &serde_json::Value,
    is_raw: bool,
) -> GlobalAdjustments {
    if js_adjustments.is_null() {
        return GlobalAdjustments::default();
    }

    let visibility = js_adjustments.get("sectionVisibility");
    let is_visible = |section: &str| -> bool {
        visibility
            .and_then(|v| v.get(section))
            .and_then(|s| s.as_bool())
            .unwrap_or(true)
    };

    let get_val = |section: &str, key: &str, scale: f32, default: Option<f64>| -> f32 {
        if is_visible(section) {
            js_adjustments[key]
                .as_f64()
                .unwrap_or(default.unwrap_or(0.0)) as f32
                / scale
        } else {
            if let Some(d) = default {
                d as f32 / scale
            } else {
                0.0
            }
        }
    };

    let curves_obj = js_adjustments.get("curves").cloned().unwrap_or_default();
    let luma_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["luma"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let red_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["red"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let green_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["green"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let blue_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["blue"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };

    let cg_obj = js_adjustments
        .get("colorGrading")
        .cloned()
        .unwrap_or_default();

    let cal_obj = js_adjustments
        .get("colorCalibration")
        .cloned()
        .unwrap_or_default();

    let color_cal_settings = if is_visible("color") {
        ColorCalibrationSettings {
            shadows_tint: cal_obj["shadowsTint"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_hue,
            red_hue: cal_obj["redHue"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_hue,
            red_saturation: cal_obj["redSaturation"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_saturation,
            green_hue: cal_obj["greenHue"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_hue,
            green_saturation: cal_obj["greenSaturation"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_saturation,
            blue_hue: cal_obj["blueHue"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_hue,
            blue_saturation: cal_obj["blueSaturation"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_calibration_saturation,
            _pad1: 0.0,
        }
    } else {
        ColorCalibrationSettings::default()
    };

    let neg_conv_enabled = js_adjustments["enableNegativeConversion"]
        .as_bool()
        .unwrap_or(false);
    let film_base_hex = js_adjustments["filmBaseColor"]
        .as_str()
        .unwrap_or("#ff8800");
    let film_base_rgb = if film_base_hex.starts_with('#') && film_base_hex.len() == 7 {
        let r = u8::from_str_radix(&film_base_hex[1..3], 16).unwrap_or(255) as f32 / 255.0;
        let g = u8::from_str_radix(&film_base_hex[3..5], 16).unwrap_or(136) as f32 / 255.0;
        let b = u8::from_str_radix(&film_base_hex[5..7], 16).unwrap_or(0) as f32 / 255.0;
        [r, g, b]
    } else {
        [1.0, 0.53, 0.0] // Default orange
    };

    let tone_mapper = js_adjustments["toneMapper"].as_str().unwrap_or("basic");
    let (pipe_to_rendering, rendering_to_pipe) = calculate_agx_matrices();

    GlobalAdjustments {
        exposure: get_val("basic", "exposure", SCALES.exposure, None),
        brightness: get_val("basic", "brightness", SCALES.brightness, None),
        contrast: get_val("basic", "contrast", SCALES.contrast, None),
        highlights: get_val("basic", "highlights", SCALES.highlights, None),
        shadows: get_val("basic", "shadows", SCALES.shadows, None),
        whites: get_val("basic", "whites", SCALES.whites, None),
        blacks: get_val("basic", "blacks", SCALES.blacks, None),

        saturation: get_val("color", "saturation", SCALES.saturation, None),
        temperature: get_val("color", "temperature", SCALES.temperature, None),
        tint: get_val("color", "tint", SCALES.tint, None),
        vibrance: get_val("color", "vibrance", SCALES.vibrance, None),

        sharpness: get_val("details", "sharpness", SCALES.sharpness, None),
        luma_noise_reduction: get_val(
            "details",
            "lumaNoiseReduction",
            SCALES.luma_noise_reduction,
            None,
        ),
        color_noise_reduction: get_val(
            "details",
            "colorNoiseReduction",
            SCALES.color_noise_reduction,
            None,
        ),

        clarity: get_val("effects", "clarity", SCALES.clarity, None),
        dehaze: get_val("effects", "dehaze", SCALES.dehaze, None),
        structure: get_val("effects", "structure", SCALES.structure, None),
        centré: get_val("effects", "centré", SCALES.centré, None),
        vignette_amount: get_val("effects", "vignetteAmount", SCALES.vignette_amount, None),
        vignette_midpoint: get_val(
            "effects",
            "vignetteMidpoint",
            SCALES.vignette_midpoint,
            Some(50.0),
        ),
        vignette_roundness: get_val(
            "effects",
            "vignetteRoundness",
            SCALES.vignette_roundness,
            Some(0.0),
        ),
        vignette_feather: get_val(
            "effects",
            "vignetteFeather",
            SCALES.vignette_feather,
            Some(50.0),
        ),
        grain_amount: get_val("effects", "grainAmount", SCALES.grain_amount, None),
        grain_size: get_val("effects", "grainSize", SCALES.grain_size, Some(25.0)),
        grain_roughness: get_val(
            "effects",
            "grainRoughness",
            SCALES.grain_roughness,
            Some(50.0),
        ),

        chromatic_aberration_red_cyan: get_val(
            "details",
            "chromaticAberrationRedCyan",
            SCALES.chromatic_aberration,
            None,
        ),
        chromatic_aberration_blue_yellow: get_val(
            "details",
            "chromaticAberrationBlueYellow",
            SCALES.chromatic_aberration,
            None,
        ),
        show_clipping: if js_adjustments["showClipping"].as_bool().unwrap_or(false) {
            1
        } else {
            0
        },
        is_raw_image: if is_raw { 1 } else { 0 },

        enable_negative_conversion: if neg_conv_enabled { 1 } else { 0 },
        film_base_r: film_base_rgb[0],
        film_base_g: film_base_rgb[1],
        film_base_b: film_base_rgb[2],
        negative_red_balance: js_adjustments["negativeRedBalance"].as_f64().unwrap_or(0.0) as f32
            / 100.0,
        negative_green_balance: js_adjustments["negativeGreenBalance"]
            .as_f64()
            .unwrap_or(0.0) as f32
            / 100.0,
        negative_blue_balance: js_adjustments["negativeBlueBalance"]
            .as_f64()
            .unwrap_or(0.0) as f32
            / 100.0,
        _pad_neg1: 0.0,
        _pad_neg2: 0.0,

        has_lut: if js_adjustments["lutPath"].is_string() {
            1
        } else {
            0
        },
        lut_intensity: js_adjustments["lutIntensity"].as_f64().unwrap_or(100.0) as f32 / 100.0,
        tonemapper_mode: if tone_mapper == "agx" { 1 } else { 0 },
        _pad_lut2: 0.0,
        _pad_lut3: 0.0,
        _pad_lut4: 0.0,
        _pad_lut5: 0.0,

        _pad_agx1: 0.0,
        _pad_agx2: 0.0,
        _pad_agx3: 0.0,
        agx_pipe_to_rendering_matrix: pipe_to_rendering,
        agx_rendering_to_pipe_matrix: rendering_to_pipe,

        _pad_cg1: 0.0,
        _pad_cg2: 0.0,
        _pad_cg3: 0.0,
        _pad_cg4: 0.0,
        color_grading_shadows: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["shadows"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_midtones: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["midtones"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_highlights: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["highlights"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_blending: if is_visible("color") {
            cg_obj["blending"].as_f64().unwrap_or(50.0) as f32 / SCALES.color_grading_blending
        } else {
            0.5
        },
        color_grading_balance: if is_visible("color") {
            cg_obj["balance"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_grading_balance
        } else {
            0.0
        },
        _pad2: 0.0,
        _pad3: 0.0,

        color_calibration: color_cal_settings,

        // Low-Light Recovery: Hot Pixels
        hot_pixel_enabled: if js_adjustments["hotPixelEnabled"].as_bool().unwrap_or(false) { 1 } else { 0 },
        hot_pixel_threshold: js_adjustments["hotPixelThreshold"].as_f64().unwrap_or(50.0) as f32 / SCALES.hot_pixel_threshold,
        hot_pixel_radius: js_adjustments["hotPixelRadius"].as_f64().unwrap_or(2.0) as f32 / SCALES.hot_pixel_radius,
        hot_pixel_mode: match js_adjustments["hotPixelMode"].as_str().unwrap_or("median") {
            "interpolate" => 1,
            "clone" => 2,
            _ => 0, // median
        },

        // Denoiser (ISO-adaptive)
        denoise_enabled: if js_adjustments["denoiseEnabled"].as_bool().unwrap_or(false) { 1 } else { 0 },
        denoise_strength: js_adjustments["denoiseStrength"].as_f64().unwrap_or(50.0) as f32 / SCALES.denoise_strength,
        denoise_detail: js_adjustments["denoiseDetail"].as_f64().unwrap_or(50.0) as f32 / SCALES.denoise_detail,
        denoise_chroma: js_adjustments["denoiseChroma"].as_f64().unwrap_or(50.0) as f32 / SCALES.denoise_chroma,
        // ISO multiplier is passed from frontend (calculated based on EXIF ISO when denoiseAutoIso is true)
        denoise_iso_multiplier: js_adjustments["denoiseIsoMultiplier"].as_f64().unwrap_or(1.0) as f32,
        _pad_denoise1: 0.0,
        _pad_denoise2: 0.0,
        _pad_denoise3: 0.0,

        // PID Enhancement: Smart Deblur
        deblur_enabled: if js_adjustments["deblurEnabled"].as_bool().unwrap_or(false) { 1 } else { 0 },
        deblur_type: match js_adjustments["deblurType"].as_str().unwrap_or("motion") {
            "focus" => 1,
            "gaussian" => 2,
            _ => 0, // motion
        },
        deblur_length: js_adjustments["deblurLength"].as_f64().unwrap_or(20.0) as f32 / SCALES.deblur_length,
        deblur_angle: js_adjustments["deblurAngle"].as_f64().unwrap_or(0.0) as f32,
        deblur_radius: js_adjustments["deblurRadius"].as_f64().unwrap_or(10.0) as f32 / SCALES.deblur_radius,
        deblur_strength: js_adjustments["deblurStrength"].as_f64().unwrap_or(50.0) as f32 / SCALES.deblur_strength,
        deblur_smoothness: js_adjustments["deblurSmoothness"].as_f64().unwrap_or(30.0) as f32 / SCALES.deblur_smoothness,
        deblur_noise_damp: js_adjustments["deblurNoiseDamp"].as_f64().unwrap_or(50.0) as f32 / SCALES.deblur_noise_damp,
        deblur_preview_size: js_adjustments["deblurPreviewSize"].as_f64().unwrap_or(256.0) as f32,
        deblur_show_kernel: if js_adjustments["deblurShowKernel"].as_bool().unwrap_or(false) { 1 } else { 0 },
        deblur_iterations: js_adjustments["deblurIterations"].as_u64().unwrap_or(10) as u32,
        _pad_deblur2: 0.0,

        hsl: if is_visible("color") {
            parse_hsl_adjustments(&js_adjustments.get("hsl").cloned().unwrap_or_default())
        } else {
            [HslColor::default(); 8]
        },
        luma_curve: convert_points_to_aligned(luma_points.clone()),
        red_curve: convert_points_to_aligned(red_points.clone()),
        green_curve: convert_points_to_aligned(green_points.clone()),
        blue_curve: convert_points_to_aligned(blue_points.clone()),
        luma_curve_count: luma_points.len() as u32,
        red_curve_count: red_points.len() as u32,
        green_curve_count: green_points.len() as u32,
        blue_curve_count: blue_points.len() as u32,
        _pad_end1: 0.0,
        _pad_end2: 0.0,
        _pad_end3: 0.0,
        _pad_end4: 0.0,
    }
}

fn get_mask_adjustments_from_json(adj: &serde_json::Value) -> MaskAdjustments {
    if adj.is_null() {
        return MaskAdjustments::default();
    }

    let visibility = adj.get("sectionVisibility");
    let is_visible = |section: &str| -> bool {
        visibility
            .and_then(|v| v.get(section))
            .and_then(|s| s.as_bool())
            .unwrap_or(true)
    };

    let get_val = |section: &str, key: &str, scale: f32| -> f32 {
        if is_visible(section) {
            adj[key].as_f64().unwrap_or(0.0) as f32 / scale
        } else {
            0.0
        }
    };

    let curves_obj = adj.get("curves").cloned().unwrap_or_default();
    let luma_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["luma"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let red_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["red"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let green_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["green"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let blue_points: Vec<serde_json::Value> = if is_visible("curves") {
        curves_obj["blue"].as_array().cloned().unwrap_or_default()
    } else {
        Vec::new()
    };
    let cg_obj = adj.get("colorGrading").cloned().unwrap_or_default();

    MaskAdjustments {
        exposure: get_val("basic", "exposure", SCALES.exposure),
        brightness: get_val("basic", "brightness", SCALES.brightness),
        contrast: get_val("basic", "contrast", SCALES.contrast),
        highlights: get_val("basic", "highlights", SCALES.highlights),
        shadows: get_val("basic", "shadows", SCALES.shadows),
        whites: get_val("basic", "whites", SCALES.whites),
        blacks: get_val("basic", "blacks", SCALES.blacks),

        saturation: get_val("color", "saturation", SCALES.saturation),
        temperature: get_val("color", "temperature", SCALES.temperature),
        tint: get_val("color", "tint", SCALES.tint),
        vibrance: get_val("color", "vibrance", SCALES.vibrance),

        sharpness: get_val("details", "sharpness", SCALES.sharpness),
        luma_noise_reduction: get_val("details", "lumaNoiseReduction", SCALES.luma_noise_reduction),
        color_noise_reduction: get_val(
            "details",
            "colorNoiseReduction",
            SCALES.color_noise_reduction,
        ),

        clarity: get_val("effects", "clarity", SCALES.clarity),
        dehaze: get_val("effects", "dehaze", SCALES.dehaze),
        structure: get_val("effects", "structure", SCALES.structure),

        _pad1: 0.0,
        _pad2: 0.0,
        _pad3: 0.0,
        _pad4: 0.0,

        _pad_cg1: 0.0,
        _pad_cg2: 0.0,
        _pad_cg3: 0.0,
        color_grading_shadows: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["shadows"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_midtones: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["midtones"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_highlights: if is_visible("color") {
            parse_color_grade_settings(&cg_obj["highlights"])
        } else {
            ColorGradeSettings::default()
        },
        color_grading_blending: if is_visible("color") {
            cg_obj["blending"].as_f64().unwrap_or(50.0) as f32 / SCALES.color_grading_blending
        } else {
            0.5
        },
        color_grading_balance: if is_visible("color") {
            cg_obj["balance"].as_f64().unwrap_or(0.0) as f32 / SCALES.color_grading_balance
        } else {
            0.0
        },
        _pad5: 0.0,
        _pad6: 0.0,

        // PID Enhancement (mask-supported)
        deblur_strength: get_val("pidenhancement", "deblurStrength", SCALES.deblur_strength),
        deblur_smoothness: adj["deblurSmoothness"].as_f64().unwrap_or(30.0) as f32 / SCALES.deblur_smoothness,
        _pad_pid1: 0.0,
        _pad_pid2: 0.0,

        hsl: if is_visible("color") {
            parse_hsl_adjustments(&adj.get("hsl").cloned().unwrap_or_default())
        } else {
            [HslColor::default(); 8]
        },
        luma_curve: convert_points_to_aligned(luma_points.clone()),
        red_curve: convert_points_to_aligned(red_points.clone()),
        green_curve: convert_points_to_aligned(green_points.clone()),
        blue_curve: convert_points_to_aligned(blue_points.clone()),
        luma_curve_count: luma_points.len() as u32,
        red_curve_count: red_points.len() as u32,
        green_curve_count: green_points.len() as u32,
        blue_curve_count: blue_points.len() as u32,
        _pad_end4: 0.0,
        _pad_end5: 0.0,
        _pad_end6: 0.0,
        _pad_end7: 0.0,
    }
}

pub fn get_all_adjustments_from_json(
    js_adjustments: &serde_json::Value,
    is_raw: bool,
) -> AllAdjustments {
    let global = get_global_adjustments_from_json(js_adjustments, is_raw);
    let mut mask_adjustments = [MaskAdjustments::default(); 11];
    let mut mask_count = 0;

    let mask_definitions: Vec<MaskDefinition> = js_adjustments
        .get("masks")
        .and_then(|m| serde_json::from_value(m.clone()).ok())
        .unwrap_or_else(Vec::new);

    for (i, mask_def) in mask_definitions
        .iter()
        .filter(|m| m.visible)
        .enumerate()
        .take(14)
    {
        mask_adjustments[i] = get_mask_adjustments_from_json(&mask_def.adjustments);
        mask_count += 1;
    }

    AllAdjustments {
        global,
        mask_adjustments,
        mask_count,
        tile_offset_x: 0,
        tile_offset_y: 0,
        mask_atlas_cols: 1,
    }
}

#[derive(Clone)]
pub struct GpuContext {
    pub device: Arc<wgpu::Device>,
    pub queue: Arc<wgpu::Queue>,
    pub limits: wgpu::Limits,
}

#[derive(Serialize, Clone)]
pub struct HistogramData {
    red: Vec<f32>,
    green: Vec<f32>,
    blue: Vec<f32>,
    luma: Vec<f32>,
}

#[tauri::command]
pub fn generate_histogram(
    state: tauri::State<AppState>,
    app_handle: tauri::AppHandle,
) -> Result<HistogramData, String> {
    let cached_preview_lock = state.cached_preview.lock().unwrap();

    if let Some(cached) = &*cached_preview_lock {
        calculate_histogram_from_image(&cached.image)
    } else {
        drop(cached_preview_lock);
        let image = state
            .original_image
            .lock()
            .unwrap()
            .as_ref()
            .ok_or("No image loaded to generate histogram")?
            .image
            .clone();

        let settings = load_settings(app_handle).unwrap_or_default();
        let preview_dim = settings.editor_preview_resolution.unwrap_or(1920);
        let preview = downscale_f32_image(&image, preview_dim, preview_dim);
        calculate_histogram_from_image(&preview)
    }
}

pub fn calculate_histogram_from_image(image: &DynamicImage) -> Result<HistogramData, String> {
    let mut red_counts = vec![0u32; 256];
    let mut green_counts = vec![0u32; 256];
    let mut blue_counts = vec![0u32; 256];
    let mut luma_counts = vec![0u32; 256];

    for pixel in image.to_rgb8().pixels() {
        let r = pixel[0] as usize;
        let g = pixel[1] as usize;
        let b = pixel[2] as usize;
        red_counts[r] += 1;
        green_counts[g] += 1;
        blue_counts[b] += 1;
        let luma_val = (0.2126 * r as f32 + 0.7152 * g as f32 + 0.0722 * b as f32).round() as usize;
        luma_counts[luma_val.min(255)] += 1;
    }

    let mut red: Vec<f32> = red_counts.into_iter().map(|c| c as f32).collect();
    let mut green: Vec<f32> = green_counts.into_iter().map(|c| c as f32).collect();
    let mut blue: Vec<f32> = blue_counts.into_iter().map(|c| c as f32).collect();
    let mut luma: Vec<f32> = luma_counts.into_iter().map(|c| c as f32).collect();

    let smoothing_sigma = 2.5;
    apply_gaussian_smoothing(&mut red, smoothing_sigma);
    apply_gaussian_smoothing(&mut green, smoothing_sigma);
    apply_gaussian_smoothing(&mut blue, smoothing_sigma);
    apply_gaussian_smoothing(&mut luma, smoothing_sigma);

    normalize_histogram_range(&mut red, 0.99);
    normalize_histogram_range(&mut green, 0.99);
    normalize_histogram_range(&mut blue, 0.99);
    normalize_histogram_range(&mut luma, 0.99);

    Ok(HistogramData {
        red,
        green,
        blue,
        luma,
    })
}

fn apply_gaussian_smoothing(histogram: &mut Vec<f32>, sigma: f32) {
    if sigma <= 0.0 {
        return;
    }

    let kernel_radius = (sigma * 3.0).ceil() as usize;
    if kernel_radius == 0 || kernel_radius >= histogram.len() {
        return;
    }

    let kernel_size = 2 * kernel_radius + 1;
    let mut kernel = vec![0.0; kernel_size];
    let mut kernel_sum = 0.0;

    let two_sigma_sq = 2.0 * sigma * sigma;
    for i in 0..kernel_size {
        let x = (i as i32 - kernel_radius as i32) as f32;
        let val = (-x * x / two_sigma_sq).exp();
        kernel[i] = val;
        kernel_sum += val;
    }

    if kernel_sum > 0.0 {
        for val in &mut kernel {
            *val /= kernel_sum;
        }
    }

    let original = histogram.clone();
    let len = histogram.len();

    for i in 0..len {
        let mut smoothed_val = 0.0;
        for k in 0..kernel_size {
            let offset = k as i32 - kernel_radius as i32;
            let sample_index = i as i32 + offset;
            let clamped_index = sample_index.clamp(0, len as i32 - 1) as usize;
            smoothed_val += original[clamped_index] * kernel[k];
        }
        histogram[i] = smoothed_val;
    }
}

fn normalize_histogram_range(histogram: &mut Vec<f32>, percentile_clip: f32) {
    if histogram.is_empty() {
        return;
    }

    let mut sorted_data = histogram.clone();
    sorted_data.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

    let clip_index = ((sorted_data.len() - 1) as f32 * percentile_clip).round() as usize;
    let max_val = sorted_data[clip_index.min(sorted_data.len() - 1)];

    if max_val > 1e-6 {
        let scale_factor = 1.0 / max_val;
        for value in histogram.iter_mut() {
            *value = (*value * scale_factor).min(1.0);
        }
    } else {
        for value in histogram.iter_mut() {
            *value = 0.0;
        }
    }
}

#[derive(Serialize, Clone)]
pub struct WaveformData {
    red: Vec<u32>,
    green: Vec<u32>,
    blue: Vec<u32>,
    luma: Vec<u32>,
    width: u32,
    height: u32,
}

#[tauri::command]
pub fn generate_waveform(
    state: tauri::State<AppState>,
    app_handle: tauri::AppHandle,
) -> Result<WaveformData, String> {
    let cached_preview_lock = state.cached_preview.lock().unwrap();

    if let Some(cached) = &*cached_preview_lock {
        calculate_waveform_from_image(&cached.image)
    } else {
        drop(cached_preview_lock);
        let image = state
            .original_image
            .lock()
            .unwrap()
            .as_ref()
            .ok_or("No image loaded to generate waveform")?
            .image
            .clone();

        let settings = load_settings(app_handle).unwrap_or_default();
        let preview_dim = settings.editor_preview_resolution.unwrap_or(1920);
        let preview = downscale_f32_image(&image, preview_dim, preview_dim);
        calculate_waveform_from_image(&preview)
    }
}

pub fn calculate_waveform_from_image(image: &DynamicImage) -> Result<WaveformData, String> {
    const WAVEFORM_WIDTH: u32 = 256;
    const WAVEFORM_HEIGHT: u32 = 256;

    if image.width() == 0 || image.height() == 0 {
        return Err("Image has zero dimensions.".to_string());
    }
    let preview_height =
        (image.height() as f32 * (WAVEFORM_WIDTH as f32 / image.width() as f32)).round() as u32;
    if preview_height == 0 {
        return Err("Image has zero height after scaling for waveform.".to_string());
    }
    let preview = image.resize(
        WAVEFORM_WIDTH,
        preview_height,
        image::imageops::FilterType::Triangle,
    );
    let rgb_image = preview.to_rgb8();

    let mut red = vec![0; (WAVEFORM_WIDTH * WAVEFORM_HEIGHT) as usize];
    let mut green = vec![0; (WAVEFORM_WIDTH * WAVEFORM_HEIGHT) as usize];
    let mut blue = vec![0; (WAVEFORM_WIDTH * WAVEFORM_HEIGHT) as usize];
    let mut luma = vec![0; (WAVEFORM_WIDTH * WAVEFORM_HEIGHT) as usize];

    for (x, _, pixel) in rgb_image.enumerate_pixels() {
        let r = pixel[0] as usize;
        let g = pixel[1] as usize;
        let b = pixel[2] as usize;

        let r_idx = (255 - r) * WAVEFORM_WIDTH as usize + x as usize;
        let g_idx = (255 - g) * WAVEFORM_WIDTH as usize + x as usize;
        let b_idx = (255 - b) * WAVEFORM_WIDTH as usize + x as usize;

        red[r_idx] += 1;
        green[g_idx] += 1;
        blue[b_idx] += 1;

        let luma_val = (0.2126 * r as f32 + 0.7152 * g as f32 + 0.0722 * b as f32).round() as usize;
        let luma_idx = (255 - luma_val.min(255)) * WAVEFORM_WIDTH as usize + x as usize;
        luma[luma_idx] += 1;
    }

    Ok(WaveformData {
        red,
        green,
        blue,
        luma,
        width: WAVEFORM_WIDTH,
        height: WAVEFORM_HEIGHT,
    })
}

pub fn perform_auto_analysis(image: &DynamicImage) -> AutoAdjustmentResults {
    let analysis_preview = downscale_f32_image(image, 1024, 1024);
    let rgb_image = analysis_preview.to_rgb8();
    let total_pixels = (rgb_image.width() * rgb_image.height()) as f64;

    let mut luma_hist = vec![0u32; 256];
    let mut mean_saturation = 0.0f32;
    let mut dull_pixel_count = 0;
    let mut brightest_pixels = Vec::with_capacity((total_pixels * 0.01) as usize);

    for pixel in rgb_image.pixels() {
        let r_f = pixel[0] as f32;
        let g_f = pixel[1] as f32;
        let b_f = pixel[2] as f32;

        let luma_val = (0.2126 * r_f + 0.7152 * g_f + 0.0722 * b_f).round() as usize;
        luma_hist[luma_val.min(255)] += 1;

        let r_norm = r_f / 255.0;
        let g_norm = g_f / 255.0;
        let b_norm = b_f / 255.0;
        let max_c = r_norm.max(g_norm.max(b_norm));
        let min_c = r_norm.min(g_norm.min(b_norm));
        if max_c > 0.0 {
            let s = (max_c - min_c) / max_c;
            mean_saturation += s;
            if s < 0.1 {
                dull_pixel_count += 1;
            }
        }
        brightest_pixels.push((luma_val, (r_f, g_f, b_f)));
    }

    if total_pixels > 0.0 {
        mean_saturation /= total_pixels as f32;
    }
    let dull_pixel_percent = dull_pixel_count as f64 / total_pixels;

    let mut black_point = 0;
    let mut white_point = 255;
    let clip_threshold = (total_pixels * 0.001) as u32;
    let mut cumulative_sum = 0u32;
    for i in 0..256 {
        cumulative_sum += luma_hist[i];
        if cumulative_sum > clip_threshold {
            black_point = i;
            break;
        }
    }
    cumulative_sum = 0;
    for i in (0..256).rev() {
        cumulative_sum += luma_hist[i];
        if cumulative_sum > clip_threshold {
            white_point = i;
            break;
        }
    }

    let mid_point = (black_point + white_point) / 2;
    let range = (white_point as f64 - black_point as f64).max(1.0);
    let mut exposure = 0.0;
    let mut contrast = 0.0;
    if range > 20.0 {
        exposure = (128.0 - mid_point as f64) * 0.35;
        let target_range = 250.0;
        if range < target_range {
            contrast = (target_range / range - 1.0) * 50.0;
        }
    }

    let shadow_percent = luma_hist[0..32].iter().sum::<u32>() as f64 / total_pixels;
    let highlight_percent = luma_hist[224..256].iter().sum::<u32>() as f64 / total_pixels;
    let mut shadows = 0.0;
    if shadow_percent > 0.05 && black_point < 10 {
        shadows = (shadow_percent * 150.0).min(80.0);
    }
    let mut highlights = 0.0;
    if highlight_percent > 0.05 && white_point > 245 {
        highlights = -(highlight_percent * 150.0).min(80.0);
    }

    brightest_pixels.sort_by(|a, b| b.0.cmp(&a.0));
    let num_brightest = (total_pixels * 0.01).ceil() as usize;
    let top_pixels = &brightest_pixels[..num_brightest.min(brightest_pixels.len())];
    let mut bright_r = 0.0;
    let mut bright_g = 0.0;
    let mut bright_b = 0.0;
    if !top_pixels.is_empty() {
        for &(_, (r, g, b)) in top_pixels {
            bright_r += r as f64;
            bright_g += g as f64;
            bright_b += b as f64;
        }
        bright_r /= top_pixels.len() as f64;
        bright_g /= top_pixels.len() as f64;
        bright_b /= top_pixels.len() as f64;
    }

    let mut temperature = 0.0;
    let mut tint = 0.0;
    if (bright_r - bright_b).abs() > 3.0 || (bright_g - (bright_r + bright_b) / 2.0).abs() > 3.0 {
        temperature = (bright_b - bright_r) * 0.4;
        tint = (bright_g - (bright_r + bright_b) / 2.0) * 0.5;
    }

    let mut vibrancy = 0.0;
    let saturation_target = 0.20;
    if mean_saturation < saturation_target {
        vibrancy = (saturation_target - mean_saturation) as f64 * 150.0;
    }
    if dull_pixel_percent > 0.5 {
        vibrancy += 10.0;
    }

    let mut dehaze = 0.0;
    if range < 128.0 && mean_saturation < 0.15 {
        dehaze = (1.0 - (range / 128.0)) * 40.0;
    }

    let mut clarity = 0.0;
    if range < 180.0 {
        clarity = (1.0 - (range / 180.0)) * 60.0;
    }

    let (width, height) = rgb_image.dimensions();
    let center_x_start = (width as f32 * 0.25) as u32;
    let center_x_end = (width as f32 * 0.75) as u32;
    let center_y_start = (height as f32 * 0.25) as u32;
    let center_y_end = (height as f32 * 0.75) as u32;
    let mut center_luma_sum = 0.0;
    let mut center_pixel_count = 0;
    let mut edge_luma_sum = 0.0;
    let mut edge_pixel_count = 0;

    for (x, y, pixel) in rgb_image.enumerate_pixels() {
        let luma = (0.2126 * pixel[0] as f32 + 0.7152 * pixel[1] as f32 + 0.0722 * pixel[2] as f32) / 255.0;
        if x >= center_x_start && x < center_x_end && y >= center_y_start && y < center_y_end {
            center_luma_sum += luma;
            center_pixel_count += 1;
        } else {
            edge_luma_sum += luma;
            edge_pixel_count += 1;
        }
    }

    let mut vignette_amount = 0.0;
    let mut centre = 0.0;
    if center_pixel_count > 0 && edge_pixel_count > 0 {
        let avg_center_luma = center_luma_sum / center_pixel_count as f32;
        let avg_edge_luma = edge_luma_sum / edge_pixel_count as f32;

        if avg_edge_luma < avg_center_luma {
            let luma_diff = avg_center_luma - avg_edge_luma;
            vignette_amount = -(luma_diff as f64 * 150.0);

            if luma_diff > 0.05 {
                centre = (luma_diff as f64 * 120.0).min(60.0);
            }
        }
    }

    AutoAdjustmentResults {
        exposure: (exposure / 20.0).clamp(-5.0, 5.0),
        contrast: contrast.clamp(0.0, 100.0),
        highlights: highlights.clamp(-100.0, 0.0),
        shadows: shadows.clamp(0.0, 100.0),
        vibrancy: vibrancy.clamp(0.0, 80.0),
        vignette_amount: vignette_amount.clamp(-100.0, 0.0),
        temperature: temperature.clamp(-100.0, 100.0),
        tint: tint.clamp(-100.0, 100.0),
        dehaze: dehaze.clamp(0.0, 100.0),
        clarity: clarity.clamp(0.0, 100.0),
        centre: centre.clamp(0.0, 100.0),
    }
}

pub fn auto_results_to_json(results: &AutoAdjustmentResults) -> serde_json::Value {
    json!({
        "exposure": results.exposure,
        "contrast": results.contrast,
        "highlights": results.highlights,
        "shadows": results.shadows,
        "vibrance": results.vibrancy,
        "vignetteAmount": results.vignette_amount,
        "clarity": results.clarity,
        "centré": results.centre,
        //"temperature": results.temperature,
        //"tint": results.tint,
        "dehaze": results.dehaze,
        "sectionVisibility": {
            "basic": true,
            "color": true,
            "effects": true
        }
    })
}

#[tauri::command]
pub fn calculate_auto_adjustments(
    state: tauri::State<AppState>,
) -> Result<serde_json::Value, String> {
    let original_image = state
        .original_image
        .lock()
        .unwrap()
        .as_ref()
        .ok_or("No image loaded for auto adjustments")?
        .image
        .clone();

    let results = perform_auto_analysis(&original_image);

    Ok(auto_results_to_json(&results))
}